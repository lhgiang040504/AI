{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2e90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67634a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"infor_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa03bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2411, 9)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the DataFrame into training and testing sets with a 70-30 split ratio\n",
    "# and specifying a random seed for reproducibility\n",
    "train, test = train_test_split(df, test_size = 0.3, random_state=40)\n",
    "\n",
    "# Split the data again to simplify the problem with curr practice\n",
    "x_train = train.iloc[:, :-1] # All columns except the last one\n",
    "y_train = train.iloc[:, -1]  # The last column\n",
    "\n",
    "x_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37db83a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220.70635726]\n",
      " [176.78106211]\n",
      " [208.00422326]\n",
      " ...\n",
      " [243.69894981]\n",
      " [189.44562637]\n",
      " [ 91.24957496]]\n"
     ]
    }
   ],
   "source": [
    "# Create Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit model to data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa61a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Multiple_LinearRegression:\n",
    "    def __init__(self, learning_rate = 0.0000001, n_iter = 1000):\n",
    "        \"\"\"\n",
    "        This is a numpy array that :\n",
    "        each column is correspond to each feature\n",
    "        each row is corresponf to each observation\n",
    "        \"\"\"\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def compute(self, features, labels):\n",
    "        \"\"\"\n",
    "        features (obs, fea)\n",
    "        labels (obs, 1)\n",
    "        \"\"\"\n",
    "        n_observation, n_feature = features.shape # [obs, fea]\n",
    "        self.weights = np.ones(n_feature).reshape(-1, 1) # (fea, 1)\n",
    "        self.bias = 0\n",
    "                \n",
    "        for iter in range(self.n_iter):\n",
    "            # Calculate the predicted values\n",
    "            labels_pred = np.dot(features, self.weights) + self.bias # (obs, 1)\n",
    "            labels = labels.reshape(n_observation, 1)\n",
    "                        \n",
    "            # Compute the gradients\n",
    "            dw = np.dot(features.T, (labels_pred - labels)) / n_observation # (fea, 1)\n",
    "            db = np.sum(labels_pred - labels) / n_observation \n",
    "            \n",
    "            # Update weights and bias\n",
    "            self.weights -= dw * self.learning_rate # Error cause wrong shape, expect (fea, 1) but return (fea, obs)\n",
    "            self.bias -= db * self.learning_rate\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        # Handle input parameters\n",
    "        # For features\n",
    "        features = features.values\n",
    "        # For lable\n",
    "        labels = labels.values\n",
    "         \n",
    "        self.compute(features, labels)\n",
    "    \n",
    "    \"\"\"\n",
    "    The @property decorator in Python is used to define \"getter\" methods for class attributes. \n",
    "    It allows you to access an attribute like a method, but without using parentheses.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def coef(self):\n",
    "        return self.weights\n",
    "    \n",
    "    @property\n",
    "    def intercept(self):\n",
    "        return self.bias\n",
    "    \n",
    "    def predict(self, features):\n",
    "        features = features.values\n",
    "        return np.dot(features, self.weights) + self.bias\n",
    "    \n",
    "    def R_Squared(label_true, label_pred):\n",
    "        \"\"\"\n",
    "        Compute R-squared (coefficient of determination) for a linear regression model.\n",
    "        \n",
    "        Parameters:\n",
    "        - label_true: Array-like, true values of the dependent variable.\n",
    "        - label_pred: Array-like, predicted values of the dependent variable from the model.\n",
    "\n",
    "        Returns:\n",
    "        - R-squared value, a float between 0 and 1.\n",
    "        \"\"\"\n",
    "        # Calculate the mean of the true values\n",
    "        mean_label_true = np.mean(label_true)\n",
    "        # Calculate the total sum of squares \n",
    "        ss_fit = np.sum((label_pred - mean_label_true)**2)\n",
    "        # Calculate the residual sum of squares\n",
    "        ss_mean = np.sum((label_true - mean_label_true)**2)\n",
    "        # Calculate R-squared\n",
    "        r_squared = 1 - (ss_fit/ss_mean)\n",
    "\n",
    "        return r_squared\n",
    "    \n",
    "    def MSE(self, label_true, label_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Squared Error (MSE) for a linear regression model.\n",
    "\n",
    "        Parameters:\n",
    "        - label_true: Array-like, true values of the dependent variable.\n",
    "        - label_pred: Array-like, predicted values of the dependent variable from the model.\n",
    "\n",
    "        Returns:\n",
    "        - Mean Squared Error (MSE), a non-negative float.\n",
    "        \"\"\"\n",
    "        label_true = label_true.values\n",
    "        mse = np.mean((label_pred - label_true)**2)\n",
    "\n",
    "        return mse\n",
    "    \n",
    "    def RMSE(self, label_true, label_pred):\n",
    "        \"\"\"\n",
    "        Compute the Root Mean Squared Error (RMSE) for a linear regression model.\n",
    "\n",
    "        Parameters:\n",
    "        - label_true: Array-like, true values of the dependent variable.\n",
    "        - label_pred: Array-like, predicted values of the dependent variable from the model.\n",
    "\n",
    "        Returns:\n",
    "        - Root Mean Squared Error (RMSE), a non-negative float.\n",
    "        \"\"\"\n",
    "        rmse = np.sqrt(self.MSE(label_true, label_pred))\n",
    "\n",
    "        return rmse\n",
    "\n",
    "    def MAE(self, label_true, label_pred):\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Error (MAE) for a linear regression model.\n",
    "\n",
    "        Parameters:\n",
    "        - label_true: Array-like, true values of the dependent variable.\n",
    "        - label_pred: Array-like, predicted values of the dependent variable from the model.\n",
    "\n",
    "        Returns:\n",
    "        - Mean Absolute Error (MAE), a non-negative float.\n",
    "        \"\"\"\n",
    "        mae = np.mean(np.abs(label_pred - label_true))\n",
    "\n",
    "        return mae\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc4a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218.08690473]\n",
      " [206.64906286]\n",
      " [178.69563439]\n",
      " ...\n",
      " [183.2193274 ]\n",
      " [214.7314077 ]\n",
      " [149.24244768]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Manual\"\"\"\n",
    "model_Manual = Multiple_LinearRegression()\n",
    "\n",
    "# Compute coeficient\n",
    "model_Manual.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Predicttion\n",
    "y_predManual = model_Manual.predict(x_test)\n",
    "\n",
    "print(y_predManual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90883bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2411,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "470dbe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4225.478259640543\n"
     ]
    }
   ],
   "source": [
    "print(model_Manual.MSE(y_test, y_predManual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ee821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
